---
title: "Ramen Reviews, NYC Airbnb, Drug Study, and Cafe Sales - Data Cleaning & Analysis"
author: "Tharina Messeroux"
date: "01/30/2024"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE) # no need to change these options
library(tidyverse)
library(readxl)
library(janitor)
library(dplyr)
```

This project covered importing, cleaning, and wrangling data using R packages like dplyr and tidyr, performing exploratory data analysis with ggplot2, running basic statistical models such as regressions and t-tests, and exporting cleaned datasets for future use. Datasets included ramen ratings, Airbnb listings, depression drug studies, and cafe sales.

## Question 1 

This data was collected from www.theramenrater.com. It provides information on different reviews of ramen products, and has variables: Review #, Brand, Variety, Style, Country, Stars, and Top Ten. 

#### (a)

Read in the Ramen data and check it carefully. 

```{r}

ramen <- read_csv("data/ramen-ratings.csv")

```
#### (b)

Rename the first variable to be "review_number", and the last variable to be "top_ten". Additionally, ensure that the Stars column is saved as a numeric variable, and remove any non-numeric entries. 

```{r}

#Rename the first variable to be "review_number", and the last variable to be "top_ten"

new_ramen <- ramen %>%
  rename(review_number = "Review #", top_ten = "Top Ten")

#creating numeric Stars column 
ramen_num <- mutate(new_ramen, Stars = as.numeric(Stars))

# Identifying observations that are missing

missing_ram <- ramen_num %>%
  filter(is.na(Stars))

# Dropping all observations that have any missing values 
no_na_ramen <- ramen_num %>%
  drop_na(Stars)

#checking if NA dropped 
missing_ram_check <- no_na_ramen %>%
  filter(is.na(Stars))


```


#### (c)

Filtering just for the the 'Nissin' ramen brand, calculate the average rating for each country of this brand. What country has the highest rating of Nissin ramen? What country has the lowest rating? 

```{r}
avg_rating_Nissin <- no_na_ramen %>%
  filter(Brand == "Nissin") %>%
  group_by(Country) %>%
  summarize(mean_rating = mean(Stars)) %>%
  arrange(mean_rating)

```

Brazil has the highest rating of Nissin ramen with an average of 4.35 

The Phillipines has the lowest rating of Nissing ramen with an average of 2.00


#### (d)

Create a new variable called "popular" which returns a 1 for entries that have a rating above or equal to 4.5 stars, and 0 for those that don't. 

```{r}
no_na_ramen <- no_na_ramen %>%
  mutate(popular = ifelse(Stars >= 4.5, 1, 0))

```

#### (e)

Calculate the average stars for popular and not popular ramen and print it below. Explain why it would be concerning if the average stars for a popular ramen was below 4.5.

```{r}

avg_rating_popular <- no_na_ramen %>%
  group_by(popular) %>%
  summarize(mean_rating = mean(Stars)) %>%
  arrange(mean_rating)

```

It would be concerning if the average stars for a popular ramen was below 4.5 because that would mean that a lot of low-rating ramen were popular 


## Question 2 

#### (a)

Read in NYC Airbnb data `AB_NYC_2019.csv`, and select only the: host_name, neighborhood_group, room_type, price, minimum_nights, and number_of_reviews. Note, the neighborhood_group variable refers to borough. 

```{r}

nyc_airbnb <- read_csv("data/AB_NYC_2019.csv")

nyc_airbnb <- select(nyc_airbnb, host_name, neighbourhood_group, room_type, price, minimum_nights, number_of_reviews)

```

#### (b)

Create a new variable called minimum_price, which combines the minimum nights and price (per night) to give the minimum amount someone could pay to stay at the Airbnb. 

```{r}

nyc_airbnb <- mutate(nyc_airbnb, minimum_price = minimum_nights*price)


```

#### (c)

Calculate the mean and median minimum_price using 'summarize'. From these results, estimate whether you expect the data to be left or right skewed? Confirm your hypothesis by creating a histogram. Note, to improve the visualization of your histogram, please remove very high prices (include only prices less than $10,000). 

```{r}

minimum_price_sum <- nyc_airbnb %>%
  summarize(mean_min_price= mean(minimum_price), 
            median_min_price= median(minimum_price))
  
minimum_price_under_10000 <- nyc_airbnb %>%
  filter(minimum_price < 10000)


ggplot(data = minimum_price_under_10000)+
  geom_histogram(aes(x = minimum_price))


```

I expect the data to be right-skewed because the mean is much greater than the median. 

#### (d)

Are all of the New York City boroughs represented in the data? Prove your conclusion using the summarize function to show the number of observations in each borough.

```{r}

nyc_boroughs <- nyc_airbnb %>%
  group_by(neighbourhood_group) %>%
  summarise(borough_obs = n())

```

Yes, all the NYC boroughs are represented in the data 


#### (e)

Plot a boxplot of price across boroughs, showing only properties less than 1,000 a night. From the graph, which borough appears to have the highest median price? Which seems to have the lowest median price? Confirm this result using summarize and report the median price by borough. 

```{r}

price_under_1000 <- nyc_airbnb %>%
  filter(price < 1000)

ggplot(data = price_under_1000) +
  geom_boxplot(aes(x = neighbourhood_group, y = price))+
  labs(x = "Price", y = "NYC Boroughs", title = "Airbnb Price per Night NYC")

#summarize and report the median price by borough. 
median_price_by_borough <- price_under_1000 %>%
  group_by(neighbourhood_group) %>%
  summarize(median_price = median(price))

```


From the graph, Manhattan appears to have the highest median price of 149 and the Bronx seems to have the lowest median price of 65. This was confirmed with a table of the prices. The other median prices were 90 for Brooklyn, and 75 for Queens and Staten Island.


#### (f)

What is the most commonly occurring host name? Re-write the code below using pipes and then report the answer in a sentence.

```{r}

host_name_repeat <- nyc_airbnb %>%
  group_by(host_name) %>%
  summarize(n = n()) %>%
  arrange(-n)

arrange(summarise(group_by(nyc_airbnb, host_name), n = n()), -n)

```

The most commonly occurring host name is Michael with 417 of the hosts being named Michael 

## Question 3

#### (a)

You have been given a dataset for a study of a potential depression drug: `STUDYDAT12014.csv`. It includes treatment and placebo status, dose, age, along with HAM-D and HAM-A scores at baseline (`baseline_hamd` and `baseline_hama`) and at the end of the study (`outcome_hamd` and `outcome_hama`). Read in this dataset (`STUDYDAT12014.csv`) and report how many variables and how many observations are in this dataset.

```{r}

depression_drug <- read_csv("data/STUDYDAT12014.csv")

```

There are 8 variables and 200 observations in this dataset.

#### (b)

The investigators are interested in analyzing subjects who are at least 30 years old but less than 40 years old, so create a dataset which contains only observations from people within this age range. Use this dataset for all subsequent analyses.

```{r}

subjects_included <- filter(depression_drug, age >= 30 & age < 40)


```

#### (c)
The treatment groups are currently labeled `pbo` and `trx`, but the researchers would like to have them labeled `Placebo` and `Drug 13XA`. Please make these changes to the dataset you created in (b)  

```{r}

depression_drug_trx <- subjects_included %>%
   mutate(treatment = recode(trx,pbo ="Placebo",trx = "Drug 13XA"))

test <- subjects_included %>%
group_by(trx) %>%
  summarize(mean_bp = mean(baseline_hama),
            median_bp = median(baseline_hama))


```

#### (d)

Create two new variables `hamd_diff` and `hama_diff` that are changes between baseline and outcome measurements for HAM-A and HAM-D. 

```{r}

depression_drug_trx <- depression_drug_trx %>%
  mutate(hamd_diff = outcome_hamd - baseline_hamd, hama_diff =  outcome_hama - baseline_hama)


```

#### (e)

The investigators are interested in assessing whether there is a difference in (1) mean HAM-A changes between treatment groups and (2) mean HAM-D changes between treatment groups. Use t-tests (unequal variance) to test the difference between treatment groups for both of these outcomes. Be sure to report the test statistic, p-value, and degrees of freedom for each test in your write-up. 

*Try your best to interpret the results of the hypothesis test correctly, but do not worry -- we will be focused on whether you reported the test statistic, p-value, and degrees of freedom using in-line code.*

```{r}


# two-sample t-test can be performed with the t.test() function:

hamd_changes <- t.test(hamd_diff ~ trx, data = depression_drug_trx)
hama_changes <- t.test(hama_diff ~ trx, data = depression_drug_trx)

# printing the returned list from t.test() will show formatted results
hamd_changes
hama_changes

```


INTERPRETATION: 

For HAMA - 
The test statistics is `r round(hama_changes$statistic,4)` , the p-value is `r round(hama_changes$p.value,4)`, and degrees of freedom is `r round(hama_changes$parameter,4)`


The p-value is `r round(hama_changes$p.value,4)`, which is greater than 0.05. Therefore, we do not have enough evidence to conclude that there is a significant difference in mean HAM-A changes between treatment groups.


For HAMD - 
The test statistics is `r round(hamd_changes$statistic,4)` , the p-value is `r round(hamd_changes$p.value,4)`, and degrees of freedom is `r round(hamd_changes$parameter,4)`

The p-value is `r round(hamd_changes$p.value,4)`, which is greater than 0.05. Therefore, we do not have enough evidence to conclude that there is a significant difference in mean HAM-D changes between treatment groups, at the 5% significance level.


## Question 4

#### (a) 

You have been provided with a dataset from a student-run cafe `cafedata.xls`. This dataset contains data from a cafe, called Executive Express, run by undergraduate business students at a Midwestern public university. It was collected over a ten-week period from January to April 2010.  Use what you have learned to read the data in, prepare it for analysis, and then calculate the necessary summary statistics to fill out the paragraph below, replacing the X's with appropriate results *using in-line coding*.

```{r}

cafe <- read_excel("data/cafedata.xls", sheet = 2)
cafe <- cafe %>%
  clean_names()

```



```{r}
# how many profitable days 
prof_sales <- cafe %>%
  mutate(profitable = ifelse(sales >= 160, "yes","no")) %>%
  filter(!is.na(profitable)) %>%
  group_by(profitable) %>%
  summarise(count = n())

prof_sales_yes <- prof_sales$count[prof_sales$profitable == "yes"]
prof_sales_no <- prof_sales$count[prof_sales$profitable == "no"]

```

Students called a day a 'profitable day', when they had at least $160 in sales. There were `r prof_sales_yes ` 'profitable' days and `r prof_sales_no` 'unprofitable' days. 


```{r}

wraps_sold <- cafe %>%
  mutate(profitable = ifelse(sales >= 160, "yes","no")) %>%
  filter(!is.na(profitable)) %>%
  group_by(profitable) %>%
  summarise(mean_wraps = mean(wraps_sold),
            sd_wraps = sd(wraps_sold))

mean_wraps_yes <- wraps_sold$mean_wraps[wraps_sold$profitable == "yes"]
mean_wraps_no <- wraps_sold$mean_wraps[wraps_sold$profitable == "no"]

sd_wraps_yes <- wraps_sold$sd_wraps[wraps_sold$profitable == "yes"]
sd_wraps_no <- wraps_sold$sd_wraps[wraps_sold$profitable == "no"]

```


On 'profitable' days, the mean number of wraps sold was `r mean_wraps_yes` with a standard deviation of `r sd_wraps_yes` On 'unprofitable' days, the mean number of wraps sold was `r mean_wraps_no` with a standard deviation of `r sd_wraps_no` 


```{r}


muffins_cookies_sold <- cafe %>%
  mutate(muffins_cookies_sold = muffins_sold + cookies_sold)

muffins_cookies_sold <- muffins_cookies_sold %>%
  mutate(profitable = ifelse(sales >= 160, "yes","no")) %>%
  filter(!is.na(profitable)) %>%
  group_by(profitable) %>%
  summarise(mean_muffins_cookies = mean(muffins_cookies_sold),
            sd_muffins_cookies = sd(muffins_cookies_sold))

mean_mc_sold_yes <- muffins_cookies_sold$mean_muffins_cookies[muffins_cookies_sold$profitable == "yes"]
mean_mc_sold_no <- muffins_cookies_sold$mean_muffins_cookies[muffins_cookies_sold$profitable == "no"]

sd_mc_sold_yes <- muffins_cookies_sold$sd_muffins_cookies[muffins_cookies_sold$profitable == "yes"]
sd_mc_sold_no <- muffins_cookies_sold$sd_muffins_cookies[muffins_cookies_sold$profitable == "no"]

```


On 'profitable days', on average they sold `r mean_mc_sold_yes` muffins and cookies combined, with a standard deviation of `r sd_mc_sold_yes`. On 'unprofitable days', on average they sold `r mean_mc_sold_no` muffins and cookies combined, with a standard deviation of `r sd_mc_sold_no` 



```{r}

coffees_sold <- cafe %>%
  mutate(profitable = ifelse(sales >= 160, "yes","no")) %>%
  filter(!is.na(profitable)) %>%
  group_by(profitable) %>%
  summarise(mean_coffees_sold = mean(coffees),
            sd_coffees_sold = sd(coffees))

mean_coffees_sold_yes <- coffees_sold$mean_coffees_sold[coffees_sold$profitable == "yes"]
mean_coffees_sold_no <- coffees_sold$mean_coffees_sold[coffees_sold$profitable == "no"]

sd_coffees_sold_yes <- coffees_sold$sd_coffees_sold[coffees_sold$profitable == "yes"]
sd_coffees_sold_no <- coffees_sold$sd_coffees_sold[coffees_sold$profitable == "no"]

```



The mean number of coffees sold on 'profitable' days was `r mean_coffees_sold_yes` with a standard deviation of `r sd_coffees_sold_yes` and the mean number of coffees sold on 'unprofitable' days was `r mean_coffees_sold_no`  with a standard deviation of `r sd_coffees_sold_no`. 


```{r}

coffees_sold <- cafe %>%
  mutate(profitable = ifelse(sales >= 160, "yes","no")) %>%
  filter(!is.na(profitable)) %>%
  group_by(profitable)

coffees_sold_sum <- coffees_sold %>%
  summarise(mean_coffees_sold = mean(coffees),
            sd_coffees_sold = sd(coffees))

wraps_sold <- cafe %>%
  mutate(profitable = ifelse(sales >= 160, "yes","no")) %>%
  filter(!is.na(profitable)) %>%
  group_by(profitable)

wraps_sold_sum <- wraps_sold %>%
  summarise(mean_wraps = mean(wraps_sold),
            sd_wraps = sd(wraps_sold))


muffins_cookies_sold <- cafe %>%
  mutate(muffins_cookies_sold = muffins_sold + cookies_sold)

muffins_cookies_sold <- muffins_cookies_sold %>%
  mutate(profitable = ifelse(sales >= 160, "yes","no")) %>%
  filter(!is.na(profitable)) %>%
  group_by(profitable)

muffins_cookies_sold_sum <- muffins_cookies_sold %>%
  summarise(mean_muffins_cookies = mean(muffins_cookies_sold),
            sd_muffins_cookies = sd(muffins_cookies_sold))

# two-sample t-test can be performed with the t.test() function:
coffees_sold_ttest <- t.test(coffees ~ profitable, data = coffees_sold)
wraps_sold_ttest <- t.test(wraps_sold ~ profitable, data = wraps_sold)
muffins_cookies_sold_ttest <- t.test(muffins_cookies_sold ~ profitable, data = muffins_cookies_sold)

#calling ttests 

coffees_sold_ttest
wraps_sold_ttest
muffins_cookies_sold_ttest


```


When comparing profitable to nonprofitable days, there was a significant difference in coffee sold (p-value = `r round(coffees_sold_ttest$p.value,4)`, t=`r round(coffees_sold_ttest$statistic,4)`, df=`r round(coffees_sold_ttest$parameter,4)`), and in wraps sold (p-value = `r round(wraps_sold_ttest$p.value,4)`, t=`r round(wraps_sold_ttest$statistic,4)`, df=`r round (wraps_sold_ttest$parameter,4)`). However, the sales of muffins and cookies did not significantly differ between profitable and nonprofitable days (p-value = `r round(muffins_cookies_sold_ttest$p.value,4)`, t=`r round(muffins_cookies_sold_ttest$statistic,4)`, df=`r round(muffins_cookies_sold_ttest$parameter,4)`), at a level of significance of 5%.

#### (b)

Create a graph that displays the distribution of coffee sales by day. Make sure the graph has the days ordered properly, as we would expect to see them on a calendar. 

```{r}

# setting factor levels, we create a new factor variable and set the order
coffees_sold_fac <- coffees_sold %>%
  mutate(day_fac = factor(day_of_week, levels = c("Mon", "Tue", "Wed", "Thu", "Fri")))
  

# this graph now has the factors ordered properly
ggplot(data = coffees_sold_fac) +
  geom_boxplot(aes(x = day_fac, y = coffees))+
  labs(x = "Days of the Week", y = "Coffee Sales", title = "Coffee Sales by Day")

```

